{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8acc5171-2d07-4008-8d2f-eb93a186d1b7",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a67aae1-e298-433f-90de-34ba8ef05eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from copy import deepcopy\n",
    "from leaf_measurements import find_lamina_width_and_leaf_length, dist_two_points\n",
    "import re\n",
    "import shutil\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a80492-4a8f-4afc-9aa0-af8451a5f469",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d320d39-5f2e-416d-8762-5018c8efa3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox(bbox,original=True):\n",
    "    if original:\n",
    "        a,b,c,d = bbox[1:]\n",
    "        bbox = [(a,b),(c,b),(c,d),(a,d)]\n",
    "    else:\n",
    "        (a,b),_,(c,d),_ = bbox\n",
    "\n",
    "    x = [a,a,c,c,a]\n",
    "    y = [b,d,d,b,b]\n",
    "    return bbox,[x,y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d6f979f-9cc5-42fa-b6f2-0192de933aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(filename,data,whole_or_partial=\"whole\",check_zeros=False):\n",
    "\n",
    "    if check_zeros:\n",
    "        results = []\n",
    "    else:\n",
    "        results = {}\n",
    "\n",
    "    if len(data) > 0:\n",
    "        if whole_or_partial == \"whole\":\n",
    "            segmentation = 'Segmentation_Whole_Leaf'\n",
    "            bbox_key = 'Whole_Leaf_BBoxes'\n",
    "            cropped = 'Whole_Leaf_Cropped'\n",
    "        else:\n",
    "            segmentation = 'Segmentation_Partial_Leaf'\n",
    "            bbox_key = 'Partial_Leaf_BBoxes'\n",
    "            cropped = 'Partial_Leaf_Cropped'\n",
    "\n",
    "        \n",
    "        if segmentation in data[filename].keys():\n",
    "            keynames = [list(v.keys())[0] for v in data[filename][segmentation]]        \n",
    "            for i,keyname in enumerate(keynames):\n",
    "                # Original bounding box:\n",
    "                bbox = data[filename][bbox_key][i]\n",
    "                bbox__ = deepcopy(bbox)\n",
    "                box_original,bbox_coords = get_bbox(bbox)\n",
    "                # Cropped image:\n",
    "                cropped_image = data[filename][cropped][i][keyname]\n",
    "                # Translated bounding box:\n",
    "                res = data[filename][segmentation][i][keyname]\n",
    "\n",
    "                if check_zeros:\n",
    "                    if len(res) > 0:\n",
    "                        results.append(1)\n",
    "                else:\n",
    "                    if len(res) > 0:\n",
    "                        name = list(res[0].keys())[0]\n",
    "                        box_translated = res[0][name]['bbox']\n",
    "                        _,bbox_coords_translated = get_bbox(box_translated,original=False)\n",
    "                        \n",
    "                        # Translated contour:\n",
    "                        polygon = res[0][name]['polygon_closed']\n",
    "                        y = polygon[:,1]\n",
    "                        x = polygon[:,0]\n",
    "                        \n",
    "                        # Approximate scale factor\n",
    "                        kx1,ky1 = np.array(box_original[0])-np.array(box_translated[0])\n",
    "                        kx2,ky2 = np.array(box_original[1])-np.array(box_translated[1])\n",
    "                        kx3,ky3 = np.array(box_original[2])-np.array(box_translated[2])\n",
    "                        kx4,ky4 = np.array(box_original[3])-np.array(box_translated[3])\n",
    "                        kx = np.average([kx1,kx2,kx3,kx4])\n",
    "                        ky = np.average([ky1,ky2,ky3,ky4])\n",
    "                        \n",
    "                        # Move contour back:\n",
    "                        polygon_moved = [x+kx,y+ky]\n",
    "                        bbox_coords_translated[0] = bbox_coords_translated[0]+kx\n",
    "                        bbox_coords_translated[1] = bbox_coords_translated[1]+ky\n",
    "                \n",
    "                        # Other traits:\n",
    "                        long = res[0][name]['long']\n",
    "                        short = res[0][name]['short']\n",
    "                        convexity = res[0][name]['convexity']\n",
    "                        concavity = res[0][name]['concavity']\n",
    "                        aspect_ratio = res[0][name]['aspect_ratio']\n",
    "                        cx,cy = res[0][name]['centroid']\n",
    "                        centroid = [cx+kx,cy+ky]\n",
    "                \n",
    "                        # Measurements:\n",
    "                        old_measurements = find_lamina_width_and_leaf_length(x, y, [cx,cy])\n",
    "                        measurements = find_lamina_width_and_leaf_length(polygon_moved[0], polygon_moved[1], centroid)\n",
    "                        ## Width\n",
    "                        ########\n",
    "                        [x1,x2],[y1,y2] = measurements[\"width\"]\n",
    "                        d_width = dist_two_points(x1, y1, x2, y2)\n",
    "                        ## Length\n",
    "                        ########\n",
    "                        [x1,x2],[y1,y2] = measurements[\"length\"]\n",
    "                        d_length = dist_two_points(x1, y1, x2, y2)\n",
    "                \n",
    "                        results.update({filename+'__'+str(i): {\"contour\": polygon_moved, \"boundingBox\": bbox_coords_translated, \"long\": long, \"short\": short,\n",
    "                                            \"convexity\": convexity, \"concavity\": concavity, \"aspect_ratio\":aspect_ratio, \"centroid\":centroid,\n",
    "                                            \"width_line\": measurements[\"width\"], \"length_line\": measurements[\"length\"], \"length_ASJ\":d_length,\n",
    "                                            \"width_ASJ\":d_width, \"perimeter\":res[0][name]['perimeter'],\"area\":res[0][name]['area'],\n",
    "                                            \"bbox_recentred\":bbox__, \"bbox_moved\":box_translated, \"contour_original_output\":polygon,\n",
    "                                                              \"scale\":[kx,ky],\"cropped_image\":cropped_image,\"centroid_old\":[cx,cy],\n",
    "                                                              \"width_line_old\": old_measurements[\"width\"], \"length_line_old\": old_measurements[\"length\"]}})\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12dd8b34-70e6-49a8-af9d-ac8af38529ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_results(results,filename,main_keys):\n",
    "    results_short = deepcopy(results)\n",
    "    all_names = list(results.keys())\n",
    "    for key in results[all_names[0]].keys():\n",
    "        if key not in main_keys:\n",
    "            for i in range(len(results)):\n",
    "                del results_short[all_names[i]][key]\n",
    "    return results_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9788ab0d-c2b6-47b1-82d4-a4e5578c1d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_file(filename):\n",
    "    filename = filename+'.jpg'\n",
    "    names = df[df['file_name']==filename]\n",
    "    try:\n",
    "        name = names['species'].iloc[0].replace(' ','_')+'_'+str(names['gbif_id'].iloc[0])\n",
    "    except:\n",
    "        try:\n",
    "            name = names['genus'].iloc[0].replace(' ','_')+'_'+str(names['gbif_id'].iloc[0])\n",
    "        except:\n",
    "            try:\n",
    "                name = names['scientificName'].iloc[0].replace(' ','_')+'_'+str(names['gbif_id'].iloc[0])\n",
    "            except:\n",
    "                name = str(gbif_id)\n",
    "    name = name.lower()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95219d41-7186-4c33-8fdd-a3e81fab1aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_table_and_get_jsons(results):\n",
    "    filename = list(results.keys())[0][:-3]\n",
    "    res = pd.DataFrame(shorten_results(results,filename,main_keys)).T\n",
    "    \n",
    "    res = res.rename(columns={'long':'length_LM','short':'width_LM','length_ASJ':'longest_length','width_ASJ':'perpendicular_width'})\n",
    "    json_table = res.median()\n",
    "    json_table['total_leaves_or_leaflets'] = int(len(res))\n",
    "    #json_table_formatted = json_table.to_json()\n",
    "    \n",
    "    final_table = res.reset_index().rename(columns={'index':'leaf_index'})\n",
    "    final_table.insert(0, \"herbarium_sheet\", new_name)    \n",
    "    try:\n",
    "        new_name = rename_file(filename)\n",
    "    except:\n",
    "        new_name = filename\n",
    "\n",
    "    return new_name,json_table,final_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c91c3db-6d5f-4166-8d91-352960f9c790",
   "metadata": {},
   "source": [
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6664766c-119c-475f-8e9d-a739afb192fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_folder_path = '/Volumes/ARCHIVE 5/numpy_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "197ade6b-a365-4222-9ae2-2a92d47fa0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(numpy_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b19add17-7a5b-4dee-baab-c2e233701aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_jsons = '/Users/arias1/Documents/Github/LeafMachine2_usual/json_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c45dbcf-4581-4a86-baa7-eaea084bda16",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_keys = ['long','short','perimeter','area','length_ASJ','width_ASJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fae75b5c-d934-4c41-8b80-b8a76a22ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/arias1/Downloads/multimedia-taxon-mapping 1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7347448-8e57-415c-b9b7-8cab118b9261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/288 [00:00<?, ?it/s]\n",
      "  0%|                                                     | 0/288 [00:00<?, ?it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 288/288 [00:48<00:00,  5.92it/s]\u001b[A\n",
      "  0%|▏                                          | 1/288 [00:49<3:57:40, 49.69s/it]\n",
      "  0%|                                                     | 0/288 [00:00<?, ?it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 288/288 [00:37<00:00,  7.70it/s]\u001b[A\n",
      "  1%|▎                                          | 2/288 [01:28<3:25:07, 43.03s/it]\n",
      "  0%|                                                     | 0/288 [00:00<?, ?it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 288/288 [00:23<00:00, 12.33it/s]\u001b[A\n",
      "  1%|▍                                          | 3/288 [01:52<2:43:24, 34.40s/it]\n",
      "  0%|                                                     | 0/288 [00:00<?, ?it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 288/288 [01:32<00:00,  3.10it/s]\u001b[A\n",
      "  1%|▌                                          | 4/288 [03:25<4:33:39, 57.81s/it]\n",
      "  0%|                                                     | 0/288 [00:00<?, ?it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 288/288 [00:30<00:00,  9.34it/s]\u001b[A\n",
      "  2%|▋                                          | 5/288 [03:57<3:48:19, 48.41s/it]\n",
      "  0%|                                                     | 0/288 [00:00<?, ?it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 288/288 [01:02<00:00,  4.58it/s]\u001b[A\n",
      "  2%|▉                                          | 6/288 [05:01<4:12:18, 53.68s/it]\n",
      "  0%|                                                     | 0/288 [00:00<?, ?it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 288/288 [00:47<00:00,  6.07it/s]\u001b[A\n",
      "  2%|█                                          | 7/288 [05:49<4:03:22, 51.96s/it]\n",
      "  0%|                                                     | 0/288 [00:00<?, ?it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 288/288 [00:25<00:00, 11.47it/s]\u001b[A\n",
      "  3%|█▏                                         | 8/288 [06:15<3:23:21, 43.58s/it]\n",
      "  0%|                                                     | 0/288 [00:00<?, ?it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 288/288 [00:39<00:00,  7.24it/s]\u001b[A\n",
      "  3%|█▎                                         | 9/288 [06:56<3:18:55, 42.78s/it]\n",
      "  0%|                                                     | 0/288 [00:00<?, ?it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 288/288 [00:45<00:00,  6.31it/s]\u001b[A\n",
      "  3%|█▍                                        | 10/288 [07:43<3:23:29, 43.92s/it]\n",
      "  0%|                                                     | 0/288 [00:00<?, ?it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 288/288 [00:35<00:00,  8.07it/s]\u001b[A\n",
      "  4%|█▌                                        | 11/288 [08:19<3:12:10, 41.63s/it]\n",
      "  0%|                                                     | 0/288 [00:00<?, ?it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 288/288 [00:37<00:00,  7.61it/s]\u001b[A\n",
      "  4%|█▊                                        | 12/288 [08:57<3:07:03, 40.66s/it]\n",
      "  0%|                                                     | 0/288 [00:00<?, ?it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 288/288 [00:19<00:00, 14.62it/s]\u001b[A\n",
      "  5%|█▉                                        | 13/288 [09:18<2:38:17, 34.54s/it]\n",
      "  0%|                                                     | 0/288 [00:00<?, ?it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "all_tables = []\n",
    "herb_names = {}\n",
    "errors = []\n",
    "for file in tqdm.tqdm(files):\n",
    "    pth = numpy_folder_path+'/'+file\n",
    "    project = np.load(pth,allow_pickle=True)\n",
    "    for index in tqdm.tqdm(range(len(project))):\n",
    "        filenames = list(project[index].keys())\n",
    "        for filename in filenames:\n",
    "            try:\n",
    "                results = get_results(filename,project[index],whole_or_partial=\"whole\")\n",
    "                if len(results) > 0:\n",
    "                    new_name,json_table,final_table = shorten_table_and_get_jsons(results)\n",
    "                    if new_name not in list(herb_names.keys()):\n",
    "                        herb_names[new_name] = 1\n",
    "                    else:\n",
    "                        k = herb_names[new_name]\n",
    "                        k = k+1\n",
    "                        herb_names[new_name] = k\n",
    "                        new_name = new_name+'_'+str(k)\n",
    "                    json_table.to_json(path_to_jsons+'/'+new_name+'.json', orient = 'split', compression = 'infer', index = 'true')\n",
    "                    all_tables.append(final_table)\n",
    "            except:\n",
    "                errors.append([file,index,filename])\n",
    "\n",
    "metadata = pd.concat(all_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1874fd1-f87e-4f27-a44f-9a114fe2e196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_LM2",
   "language": "python",
   "name": "venv_lm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
